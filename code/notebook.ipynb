{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1f99a0e48a9345",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:50:06.579138Z",
     "start_time": "2025-05-27T08:50:04.212245Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from paddleocr import PaddleOCR\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40e65301a96572",
   "metadata": {},
   "source": [
    "Read video and capture frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e3672d498f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"../assets/成绩单.mp4\"\n",
    "output_dir = \"../frames\"\n",
    "interval = 5\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    if frame_count % interval == 0:\n",
    "        filename = os.path.join(output_dir, f\"frame_{saved_count:03d}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Saved {filename}\")\n",
    "        saved_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e973161dd339",
   "metadata": {},
   "source": [
    "Frame enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d447ad9c42af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path = sorted([os.path.join('../frames', f) for f in os.listdir('../frames') if f.endswith(\".jpg\")])\n",
    "\n",
    "if not os.path.exists('../enhanced'):\n",
    "    os.makedirs('../enhanced')\n",
    "\n",
    "idx = 0\n",
    "for f_path in frame_path:\n",
    "    img = cv2.imread(f_path)\n",
    "\n",
    "    # 灰度化\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 提高对比度（CLAHE）\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "\n",
    "    # 锐化\n",
    "    blurred = cv2.GaussianBlur(enhanced, (7, 7), 10.0)\n",
    "    sharpened = cv2.addWeighted(enhanced, 2, blurred, -0.5, 0)\n",
    "\n",
    "    filename = os.path.join('../enhanced', f\"enhanced_frame_{idx:03d}.jpg\")\n",
    "    cv2.imwrite(filename, sharpened)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Processed {filename}\")\n",
    "    idx += 1\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68b80e4c99dc57f",
   "metadata": {},
   "source": [
    "> Here we introduce manual image selection and reshape for the following OCR step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2171d42",
   "metadata": {},
   "source": [
    "OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b107a48cbc5fd0",
   "metadata": {},
   "source": [
    "Model: PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff31c737026f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_to_dataframe(img_path, y_thresh=10):\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang='ch')\n",
    "    result = ocr.ocr(img_path, cls=True)\n",
    "\n",
    "    if not result or result[0] is None:\n",
    "        print(f\"[!] No OCR result for {img_path}\")\n",
    "        return None\n",
    "\n",
    "    boxes = result[0]\n",
    "    data = []\n",
    "    for box in boxes:\n",
    "        (x0, y0), (x1, y1), (x2, y2), (x3, y3) = box[0]\n",
    "        text = box[1][0]\n",
    "        conf = box[1][1]\n",
    "        x_center = (x0 + x2) / 2\n",
    "        y_center = (y0 + y2) / 2\n",
    "        data.append((text, conf, x_center, y_center))\n",
    "\n",
    "    data = sorted(data, key=lambda x: x[3])\n",
    "\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    for i, item in enumerate(data):\n",
    "        if i == 0:\n",
    "            current_row.append(item)\n",
    "            continue\n",
    "        _, _, _, y = item\n",
    "        _, _, _, prev_y = data[i - 1]\n",
    "\n",
    "        if abs(y - prev_y) > y_thresh:\n",
    "            rows.append(current_row)\n",
    "            current_row = [item]\n",
    "        else:\n",
    "            current_row.append(item)\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    final_table = []\n",
    "    for row in rows:\n",
    "        sorted_row = sorted(row, key=lambda x: x[2])\n",
    "        texts = [cell[0] for cell in sorted_row]\n",
    "        final_table.append(texts)\n",
    "\n",
    "    return pd.DataFrame(final_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a484e88",
   "metadata": {},
   "source": [
    "Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596bba9d119a7b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T08:54:05.916057Z",
     "start_time": "2025-05-27T08:52:58.992864Z"
    }
   },
   "outputs": [],
   "source": [
    "img_dir = \"../imgs\"\n",
    "img_paths = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "dfs = []\n",
    "for idx, img_path in enumerate(img_paths):\n",
    "    df = ocr_to_dataframe(img_path)\n",
    "    if df is not None:\n",
    "        dfs.append(df)\n",
    "        print(\"df shape: \", df.shape, \"\\n\")\n",
    "        print(f\"[✓] OCR Done: {img_path}\")\n",
    "    else:\n",
    "        print(f\"[!] Skipped: {img_path}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0efce1755b2682",
   "metadata": {},
   "source": [
    "Concat and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c8baf223ed518",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rows = max(df.shape[0] for df in dfs)\n",
    "dfs = [df.reindex(index=range(max_rows)) for df in dfs]\n",
    "merged_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "output_dir = \"../output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "merged_df.to_csv(os.path.join(output_dir, \"ocr_table.csv\"), index=False, header=False)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
